{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show ALL outputs in cell, not only last result\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_filepath = \"../../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set relative path mapping for module imports\n",
    "import sys\n",
    "\n",
    "sys.path.append(relative_filepath)\n",
    "\n",
    "#for path in sys.path:\n",
    "#    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pickled combined data\n",
    "X_y_data = pd.read_pickle(relative_filepath + \"data/interim/step_3a/X_y_data.pkl\")\n",
    "\n",
    "# Read in pickled train data\n",
    "X_y_train = pd.read_pickle(relative_filepath + \"data/interim/step_3a/X_y_train.pkl\")\n",
    "\n",
    "# Read in pickled test data\n",
    "X_y_test = pd.read_pickle(relative_filepath + \"data/interim/step_3a/X_y_test.pkl\")\n",
    "\n",
    "# Recap data structure\n",
    "X_y_data.head()\n",
    "X_y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 'No missing data'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dict_ml_missing_data = json.load(open(relative_filepath + \"reports/dicts/dict_ml_missing_data.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>15.22</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.07152</td>\n",
       "      <td>...</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.17000</td>\n",
       "      <td>0.23560</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.048190</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.05852</td>\n",
       "      <td>...</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.30300</td>\n",
       "      <td>0.18040</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.68</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.05922</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>10.32</td>\n",
       "      <td>16.35</td>\n",
       "      <td>65.31</td>\n",
       "      <td>324.9</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.01012</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.06201</td>\n",
       "      <td>...</td>\n",
       "      <td>21.77</td>\n",
       "      <td>71.12</td>\n",
       "      <td>384.9</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.08842</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.07399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>11.85</td>\n",
       "      <td>17.46</td>\n",
       "      <td>75.54</td>\n",
       "      <td>432.7</td>\n",
       "      <td>0.08372</td>\n",
       "      <td>0.05642</td>\n",
       "      <td>0.02688</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.05715</td>\n",
       "      <td>...</td>\n",
       "      <td>25.75</td>\n",
       "      <td>84.35</td>\n",
       "      <td>517.8</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.17580</td>\n",
       "      <td>0.13160</td>\n",
       "      <td>0.09140</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>0.07007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "562        15.22         30.62          103.40      716.9          0.10480   \n",
       "291        14.96         19.10           97.03      687.3          0.08992   \n",
       "16         14.68         20.13           94.74      684.5          0.09867   \n",
       "546        10.32         16.35           65.31      324.9          0.09434   \n",
       "293        11.85         17.46           75.54      432.7          0.08372   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "562           0.20870         0.25500             0.094290         0.2128   \n",
       "291           0.09823         0.05940             0.048190         0.1879   \n",
       "16            0.07200         0.07395             0.052590         0.1586   \n",
       "546           0.04994         0.01012             0.005495         0.1885   \n",
       "293           0.05642         0.02688             0.022800         0.1875   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "562                 0.07152  ...          42.79           128.70       915.0   \n",
       "291                 0.05852  ...          26.19           109.10       809.8   \n",
       "16                  0.05922  ...          30.88           123.40      1138.0   \n",
       "546                 0.06201  ...          21.77            71.12       384.9   \n",
       "293                 0.05715  ...          25.75            84.35       517.8   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "562            0.1417            0.79170          1.17000   \n",
       "291            0.1313            0.30300          0.18040   \n",
       "16             0.1464            0.18710          0.29140   \n",
       "546            0.1285            0.08842          0.04384   \n",
       "293            0.1369            0.17580          0.13160   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "562               0.23560          0.4089                  0.14090       0  \n",
       "291               0.14890          0.2962                  0.08472       1  \n",
       "16                0.16090          0.3029                  0.08216       0  \n",
       "546               0.02381          0.2681                  0.07399       1  \n",
       "293               0.09140          0.3101                  0.07007       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(426, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#values for config dict\n",
    "input_dfs = [X_y_data,\n",
    "             X_y_train,\n",
    "             X_y_test]\n",
    "\n",
    "target = \"classLabel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Checklist"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://www.justintodata.com/data-cleaning-python-ultimate-guide/\n",
    "\n",
    "Table Of Contents\n",
    "Missing data\n",
    "Irregular data (Outliers)\n",
    "Unnecessary data\n",
    "Unnecessary type #1: Uninformative / Repetitive\n",
    "Unnecessary type #2: Irrelevant\n",
    "Unnecessary type #3: Duplicates\n",
    "Inconsistent data\n",
    "Inconsistent type #1: Capitalization\n",
    "Inconsistent type #2: Formats\n",
    "Inconsistent type #3: Categorical Values\n",
    "Inconsistent type #4: Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://elitedatascience.com/data-cleaning\n",
    "\n",
    "Remove Unwanted observations\n",
    "    Duplicate observations\n",
    "    Irrelevant observations\n",
    "    \n",
    "Fix Structural Errors\n",
    "\n",
    "Filter Unwanted Outliers\n",
    "\n",
    "Handle Missing Data\n",
    "    Missing categorical data\n",
    "    Missing numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification, load_breast_cancer\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y = True, as_frame=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_data_cleaning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6dd41c38031e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_data_cleaning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_data_cleaning' is not defined"
     ]
    }
   ],
   "source": [
    "dict_data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate count statistics of duplicate entries\n",
    "print (\"## Number of duplicate rows ## \\n\")\n",
    "if len(X_y_data[X_y_data.duplicated()]) > 0:\n",
    "    print(\"Number of duplicated observations: \", len(X_y_data[X_y_data.duplicated()]))\n",
    "    X_y_data[X_y_data.duplicated(keep=False)].sort_values(by=list(X_y_data.columns)).head()\n",
    "else:\n",
    "    print(\"No duplicated observations found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_y_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing/Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_data_cleaning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6dd41c38031e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_data_cleaning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_data_cleaning' is not defined"
     ]
    }
   ],
   "source": [
    "#dict_data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with a lot of missing values.\n",
    "ind_missing = df[df['num_missing'] > 35].index\n",
    "df_less_missing_rows = df.drop(ind_missing, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hospital_beds_raion has a lot of missing.\n",
    "# If we want to drop.\n",
    "cols_to_drop = ['hospital_beds_raion']\n",
    "df_less_hos_beds_raion = df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with the median.\n",
    "med = df['life_sq'].median()\n",
    "print(med)\n",
    "df['life_sq'] = df['life_sq'].fillna(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing values and create the missing value indicator variables for each numeric column.\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "numeric_cols = df_numeric.columns.values\n",
    "\n",
    "for col in numeric_cols:\n",
    "    missing = df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    \n",
    "    if num_missing > 0:  # only do the imputation for the columns that have missing values.\n",
    "        print('imputing missing values for: {}'.format(col))\n",
    "        df['{}_ismissing'.format(col)] = missing\n",
    "        med = df[col].median()\n",
    "        df[col] = df[col].fillna(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-624b1b4a7695>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-624b1b4a7695>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    view raw\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# impute the missing values and create the missing value indicator variables for each non-numeric column.\n",
    "df_non_numeric = df.select_dtypes(exclude=[np.number])\n",
    "non_numeric_cols = df_non_numeric.columns.values\n",
    "\n",
    "for col in non_numeric_cols:\n",
    "    missing = df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    \n",
    "    if num_missing > 0:  # only do the imputation for the columns that have missing values.\n",
    "        print('imputing missing values for: {}'.format(col))\n",
    "        df['{}_ismissing'.format(col)] = missing\n",
    "        \n",
    "        top = df[col].describe()['top'] # impute with the most frequent value.\n",
    "        df[col] = df[col].fillna(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical\n",
    "df['sub_area'] = df['sub_area'].fillna('_MISSING_')\n",
    "\n",
    "\n",
    "# numeric\n",
    "df['life_sq'] = df['life_sq'].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This article covers 7 ways to handle missing values in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deleting Rows with missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Impute missing values for continuous variable\n",
    "\n",
    "data[\"Age\"] = data[\"Age\"].replace(np.NaN, data[\"Age\"].mean())\n",
    "data[\"Age\"] = data[\"Age\"].replace(np.NaN, data[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Impute missing values for categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Other Imputation Methods\n",
    "\n",
    "data[\"Age\"] = data[\"Age\"].fillna(method='ffill')\n",
    "data[\"Age\"] = data[\"Age\"].interpolate(method='linear', limit_direction='forward', axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Using Algorithms that support missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction of missing values\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "data = data[[\"Survived\", \"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\", \"Age\"]]\n",
    "\n",
    "data[\"Sex\"] = [1 if x==\"male\" else 0 for x in data[\"Sex\"]]\n",
    "\n",
    "test_data = data[data[\"Age\"].isnull()]\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "y_train = data[\"Age\"]\n",
    "X_train = data.drop(\"Age\", axis=1)\n",
    "X_test = test_data.drop(\"Age\", axis=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imputation using Deep Learning Library — Datawig\n",
    "\n",
    "import pandas as pd\n",
    "#pip install datawig\n",
    "import datawig\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "df_train, df_test = datawig.utils.random_split(data)\n",
    "\n",
    "#Initialize a SimpleImputer model\n",
    "imputer = datawig.SimpleImputer(\n",
    "    input_columns=['Pclass','SibSp','Parch'], # column(s) containing information about the column we want to impute\n",
    "    output_column= 'Age', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=df_train, num_epochs=50)\n",
    "\n",
    "#Impute missing values and return original dataframe with predictions\n",
    "imputed = imputer.predict(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do All Data Cleaning on Only Train Set and Apply Calculations to Validation/Test Later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_ml_data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/700/1*_RA3mCS30Pr0vUxbp25Yxw.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "Image(url= \"https://miro.medium.com/max/700/1*_RA3mCS30Pr0vUxbp25Yxw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 'No missing data'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ml_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Redundant/Irrelevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ml_redundant_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Redundant/Irrelevant Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ml_redundant_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ml_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ml_class_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Category Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ml_category_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Rescaling: Standardise/Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ml_rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Other Distribution Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO LOOK INTO NEXT PREPROCESSING PIPELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET ENCODER LOOK INTO THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS FOR ALL PREPROCESSING STEPS TO FEED INTO PIPELINES\n",
    "\n",
    "imputers\n",
    "scaler\n",
    "pca\n",
    "smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "('features', FeatureUnion ([\n",
    "     ('Cat Columns', Pipeline([\n",
    "          ('Category Extractor', TypeSelector(np.number)),\n",
    "                 ('Impute Zero', SimpleImputer(strategy=\"constant\", fill_value=0))\n",
    "                                    ])),\n",
    "('Numerics', Pipeline([\n",
    "      ('Numeric Extractor', TypeSelector(\"category\")),\n",
    "          ('Impute Missing', SimpleImputer(strategy=\"constant\", fill_value='missing'))\n",
    "          ]))        \n",
    "     ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = 'median', fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(strategy='mean'))\n",
    "      ,('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(strategy='constant'))\n",
    "      ,('encoder', OrdinalEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = data.select_dtypes(include=['object']).drop(['Loan_Status'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "categorical_features = ['season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "   transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_features)\n",
    "   ,('categorical', categorical_transformer, categorical_features)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "pipeline = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('regressor',RandomForestRegressor())\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
